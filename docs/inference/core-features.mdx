---
---

<Card title="ðŸ“„ï¸Function CallingIn this tutorial, you'll learn how to connect large language models to external tools using our chat completions API. This includes:" href="/docs/inference/functions" />

<Card title="ðŸ“„ï¸Streaming and Parallel CallsIn the previous tutorial, we learned the basics for defining and executing functions using our chat completions API." href="/docs/inference/streaming-functions">
  ##
</Card>

<Card title="ðŸ“„ï¸EmbeddingsIn this tutorial, you'll learn how to:" href="/docs/inference/embeddings">
  ##
</Card>

<Card title="ðŸ“„ï¸Dynamic VariablesDynamic variables let you configure a template for your agent's behavior. You can re-use the same general instructions while dynamically personalizing every conversation your agent has." href="/docs/inference/ai-assistants/dynamic-variables">
  ##
</Card>

<Card title="ðŸ“„ï¸Importing AssistantsIf you have voice assistants with another provider, you can import them to Telnyx in the portal or via API." href="/docs/inference/ai-assistants/importing">
  ##
</Card>

<Card title="ðŸ“„ï¸IntegrationsConnect your Telnyx AI assistants with enterprise platforms like Salesforce, ServiceNow, Jira, and HubSpot to automate workflows and enhance customer experiences." href="/docs/inference/ai-assistants/integrations">
  ##
</Card>

<Card title="ðŸ“„ï¸WorkflowManage AI assistant workflows with visual flowcharts. Configure tools, design conversation flows, and optimize call routing for your voice AI assistant." href="/docs/inference/ai-assistants/workflows">
  ##
</Card>

<Card title="ðŸ“„ï¸MemoryMemory enables your AI assistant to recall essential details from past conversations. Instead of starting each phone call or text exchange from scratch, your AI assistant naturally continues previous discussions." href="/docs/inference/ai-assistants/memory">
  ##
</Card>

<Card title="ðŸ—ƒï¸AI Insights4 items" href="/docs/inference/ai-insights">
  ##
</Card>

<Card title="ðŸ“„ï¸Agent HandoffEnable seamless AI-to-AI handoffs with specialized assistants working together in a single conversation, providing expert-level support across multiple domains." href="/docs/inference/ai-assistants/agent-handoff">
  ##
</Card>

<Card title="ðŸ“„ï¸Testing, Versions & Traffic DistributionThis guide walks you through testing your AI assistant before production deployment and managing live traffic distribution between different versions. You'll learn how to create tests, iterate on your assistant, and safely roll out changes using A/B testing." href="/docs/inference/ai-assistants/version-testing-traffic-distribution">
  ##
</Card>

<Card title="ðŸ“„ï¸Custom LLMs for AssistantsConfigure Azure OpenAI, AWS Bedrock, Baseten, or any OpenAI-compatible endpoint as a custom LLM provider for your Telnyx AI assistants." href="/docs/inference/ai-assistants/custom-llm">
  ##
</Card>
